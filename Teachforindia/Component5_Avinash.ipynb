{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb \n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK : Make a final decision on the model to be employed for this purpose\n",
    "Based on your work done in the previous components and tasks in this Menternship, you must now make a final decision on which model must be used to predict employee performance.\n",
    "\n",
    "You will be required to document the analysis you have from the application of the models in the precious component, and as to why the algorithm you have chosen makes the most sense.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data_standard = pd.read_csv('scaled_data_standard.csv', index_col='Unnamed: 0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_score(df):\n",
    "    X = df.drop(['KPIs_met >80%'], axis=1)\n",
    "    y = df['KPIs_met >80%']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train the XGBoost model\n",
    "    xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and evaluate\n",
    "    y_pred_xgb = xgb_model.predict(X_test)\n",
    "    accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "    \n",
    "\n",
    "\n",
    "    # Train the CatBoost model\n",
    "    catboost_model = CatBoostClassifier(silent=True)\n",
    "    catboost_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and evaluate\n",
    "    y_pred_catboost = catboost_model.predict(X_test)\n",
    "    accuracy_catboost = accuracy_score(y_test, y_pred_catboost)\n",
    "    \n",
    "\n",
    "\n",
    "    # Train the LightGBM model\n",
    "    lgb_model = lgb.LGBMClassifier()\n",
    "    lgb_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and evaluate\n",
    "    y_pred_lgb = lgb_model.predict(X_test)\n",
    "    accuracy_lgb = accuracy_score(y_test, y_pred_lgb)\n",
    "    \n",
    "    #accuracy scores\n",
    "    print(f\"XGBoost Accuracy: {accuracy_xgb}\")\n",
    "    print(f\"CatBoost Accuracy: {accuracy_catboost}\")\n",
    "    print(f\"LightGBM Accuracy: {accuracy_lgb}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SUNIL\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [13:36:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6715, number of negative: 12077\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001622 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 206\n",
      "[LightGBM] [Info] Number of data points in the train set: 18792, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.357333 -> initscore=-0.586959\n",
      "[LightGBM] [Info] Start training from score -0.586959\n",
      "XGBoost Accuracy: 0.6998722860791826\n",
      "CatBoost Accuracy: 0.7041294167730949\n",
      "LightGBM Accuracy: 0.7075351213282248\n"
     ]
    }
   ],
   "source": [
    "acc_score(scaled_data_standard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Employee Performance Prediction\n",
    "\n",
    "## Introduction\n",
    "This document outlines the process and decision-making involved in selecting the best machine learning model to predict employee performance. The target variable is the employee's performance rating, and the dataset includes various demographic and job-related features.\n",
    "\n",
    "## Data Preparation\n",
    "- **Cleaning:** Handled missing values and removed duplicates.\n",
    "- **Encoding:** Used Label Encoding for the `region` column due to its high cardinality and Ordinal Encoding to `education`.\n",
    "- **Scaling:** Applied Standard Scaling to numerical features.\n",
    "\n",
    "## Model Evaluation\n",
    "Three models were evaluated:\n",
    "1. **XGBoost**\n",
    "2. **CatBoost**\n",
    "3. **LightGBM**\n",
    "\n",
    "### Accuracy Results\n",
    "- **XGBoost Accuracy:** `0.70`\n",
    "- **CatBoost Accuracy:** `0.70`\n",
    "- **LightGBM Accuracy:** `0.71`\n",
    "\n",
    "## Comparison and Decision\n",
    "### XGBoost\n",
    "- **Pros:** Robust performance with tuning, handles various data types.\n",
    "- **Cons:** Slower training, requires more tuning.\n",
    "\n",
    "### CatBoost\n",
    "- **Pros:** Natively handles categorical data, less tuning required, robust performance.\n",
    "- **Cons:** Slower on extremely large datasets.\n",
    "\n",
    "### LightGBM\n",
    "- **Pros:** Fast training, excellent scalability.\n",
    "- **Cons:** Sensitive to overfitting, requires careful tuning.\n",
    "\n",
    "### Final Decision\n",
    "CatBoost is chosen due to its ease of use, robust performance, and reduced risk of overfitting. It is expected to provide reliable predictions for employee performance with minimal preprocessing and tuning efforts.\n",
    "\n",
    "## Conclusion\n",
    "CatBoost is selected as the optimal model for predicting employee performance. Its advantages in handling categorical data and robust performance make it well-suited for this task.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
